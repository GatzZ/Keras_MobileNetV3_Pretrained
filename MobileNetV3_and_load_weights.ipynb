{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T14:00:43.181183Z",
     "start_time": "2020-02-24T14:00:36.475981Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liew/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load graph\n",
      "WARNING:tensorflow:From <ipython-input-1-1f6bfaafa581>:9: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.framework import tensor_util\n",
    "\n",
    "# path to your .pb file\n",
    "GRAPH_PB_PATH = './v3-small_224_1.0_float/v3-small_224_1.0_float.pb'\n",
    "with tf.Session() as sess:\n",
    "    print(\"load graph\")\n",
    "    with gfile.FastGFile(GRAPH_PB_PATH, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        sess.graph.as_default()\n",
    "        tf.import_graph_def(graph_def, name='')\n",
    "        graph_nodes = [n for n in graph_def.node]\n",
    "\n",
    "wts = [n for n in graph_nodes if n.op=='Const']\n",
    "const_weights = []\n",
    "for n in wts:\n",
    "    const_weights.append((n.name, tensor_util.MakeNdarray(n.attr['value'].tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T14:00:55.621848Z",
     "start_time": "2020-02-24T14:00:55.349832Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobilenetV3/Conv/weights (3, 3, 3, 16)\n",
      "MobilenetV3/Conv/BatchNorm/gamma (16,)\n",
      "MobilenetV3/Conv/BatchNorm/beta (16,)\n",
      "MobilenetV3/Conv/BatchNorm/moving_mean (16,)\n",
      "MobilenetV3/Conv/BatchNorm/moving_variance (16,)\n",
      "MobilenetV3/Conv/hard_swish/add/y ()\n",
      "MobilenetV3/Conv/hard_swish/mul_1/y ()\n",
      "MobilenetV3/expanded_conv/depthwise/depthwise_weights (3, 3, 16, 1)\n",
      "MobilenetV3/expanded_conv/depthwise/BatchNorm/gamma (16,)\n",
      "MobilenetV3/expanded_conv/depthwise/BatchNorm/beta (16,)\n",
      "MobilenetV3/expanded_conv/depthwise/BatchNorm/moving_mean (16,)\n",
      "MobilenetV3/expanded_conv/depthwise/BatchNorm/moving_variance (16,)\n",
      "MobilenetV3/expanded_conv/squeeze_excite/Conv/weights (1, 1, 16, 8)\n",
      "MobilenetV3/expanded_conv/squeeze_excite/Conv/biases (8,)\n",
      "MobilenetV3/expanded_conv/squeeze_excite/Conv_1/weights (1, 1, 8, 16)\n",
      "MobilenetV3/expanded_conv/squeeze_excite/Conv_1/biases (16,)\n",
      "MobilenetV3/expanded_conv/squeeze_excite/Conv_1/add/y ()\n",
      "MobilenetV3/expanded_conv/squeeze_excite/Conv_1/mul/y ()\n",
      "MobilenetV3/expanded_conv/project/weights (1, 1, 16, 16)\n",
      "MobilenetV3/expanded_conv/project/BatchNorm/gamma (16,)\n",
      "MobilenetV3/expanded_conv/project/BatchNorm/beta (16,)\n",
      "MobilenetV3/expanded_conv/project/BatchNorm/moving_mean (16,)\n",
      "MobilenetV3/expanded_conv/project/BatchNorm/moving_variance (16,)\n",
      "MobilenetV3/expanded_conv_1/expand/weights (1, 1, 16, 72)\n",
      "MobilenetV3/expanded_conv_1/expand/BatchNorm/gamma (72,)\n",
      "MobilenetV3/expanded_conv_1/expand/BatchNorm/beta (72,)\n",
      "MobilenetV3/expanded_conv_1/expand/BatchNorm/moving_mean (72,)\n",
      "MobilenetV3/expanded_conv_1/expand/BatchNorm/moving_variance (72,)\n",
      "MobilenetV3/expanded_conv_1/depthwise/depthwise_weights (3, 3, 72, 1)\n",
      "MobilenetV3/expanded_conv_1/depthwise/BatchNorm/gamma (72,)\n",
      "MobilenetV3/expanded_conv_1/depthwise/BatchNorm/beta (72,)\n",
      "MobilenetV3/expanded_conv_1/depthwise/BatchNorm/moving_mean (72,)\n",
      "MobilenetV3/expanded_conv_1/depthwise/BatchNorm/moving_variance (72,)\n",
      "MobilenetV3/expanded_conv_1/project/weights (1, 1, 72, 24)\n",
      "MobilenetV3/expanded_conv_1/project/BatchNorm/gamma (24,)\n",
      "MobilenetV3/expanded_conv_1/project/BatchNorm/beta (24,)\n",
      "MobilenetV3/expanded_conv_1/project/BatchNorm/moving_mean (24,)\n",
      "MobilenetV3/expanded_conv_1/project/BatchNorm/moving_variance (24,)\n",
      "MobilenetV3/expanded_conv_2/expand/weights (1, 1, 24, 88)\n",
      "MobilenetV3/expanded_conv_2/expand/BatchNorm/gamma (88,)\n",
      "MobilenetV3/expanded_conv_2/expand/BatchNorm/beta (88,)\n",
      "MobilenetV3/expanded_conv_2/expand/BatchNorm/moving_mean (88,)\n",
      "MobilenetV3/expanded_conv_2/expand/BatchNorm/moving_variance (88,)\n",
      "MobilenetV3/expanded_conv_2/depthwise/depthwise_weights (3, 3, 88, 1)\n",
      "MobilenetV3/expanded_conv_2/depthwise/BatchNorm/gamma (88,)\n",
      "MobilenetV3/expanded_conv_2/depthwise/BatchNorm/beta (88,)\n",
      "MobilenetV3/expanded_conv_2/depthwise/BatchNorm/moving_mean (88,)\n",
      "MobilenetV3/expanded_conv_2/depthwise/BatchNorm/moving_variance (88,)\n",
      "MobilenetV3/expanded_conv_2/project/weights (1, 1, 88, 24)\n",
      "MobilenetV3/expanded_conv_2/project/BatchNorm/gamma (24,)\n",
      "MobilenetV3/expanded_conv_2/project/BatchNorm/beta (24,)\n",
      "MobilenetV3/expanded_conv_2/project/BatchNorm/moving_mean (24,)\n",
      "MobilenetV3/expanded_conv_2/project/BatchNorm/moving_variance (24,)\n",
      "MobilenetV3/expanded_conv_3/expand/weights (1, 1, 24, 96)\n",
      "MobilenetV3/expanded_conv_3/expand/BatchNorm/gamma (96,)\n",
      "MobilenetV3/expanded_conv_3/expand/BatchNorm/beta (96,)\n",
      "MobilenetV3/expanded_conv_3/expand/BatchNorm/moving_mean (96,)\n",
      "MobilenetV3/expanded_conv_3/expand/BatchNorm/moving_variance (96,)\n",
      "MobilenetV3/expanded_conv_3/expand/hard_swish/add/y ()\n",
      "MobilenetV3/expanded_conv_3/expand/hard_swish/mul_1/y ()\n",
      "MobilenetV3/expanded_conv_3/depthwise/depthwise_weights (5, 5, 96, 1)\n",
      "MobilenetV3/expanded_conv_3/depthwise/BatchNorm/gamma (96,)\n",
      "MobilenetV3/expanded_conv_3/depthwise/BatchNorm/beta (96,)\n",
      "MobilenetV3/expanded_conv_3/depthwise/BatchNorm/moving_mean (96,)\n",
      "MobilenetV3/expanded_conv_3/depthwise/BatchNorm/moving_variance (96,)\n",
      "MobilenetV3/expanded_conv_3/depthwise/hard_swish/add/y ()\n",
      "MobilenetV3/expanded_conv_3/depthwise/hard_swish/mul_1/y ()\n",
      "MobilenetV3/expanded_conv_3/squeeze_excite/Conv/weights (1, 1, 96, 24)\n",
      "MobilenetV3/expanded_conv_3/squeeze_excite/Conv/biases (24,)\n",
      "MobilenetV3/expanded_conv_3/squeeze_excite/Conv_1/weights (1, 1, 24, 96)\n",
      "MobilenetV3/expanded_conv_3/squeeze_excite/Conv_1/biases (96,)\n",
      "MobilenetV3/expanded_conv_3/squeeze_excite/Conv_1/add/y ()\n",
      "MobilenetV3/expanded_conv_3/squeeze_excite/Conv_1/mul/y ()\n",
      "MobilenetV3/expanded_conv_3/project/weights (1, 1, 96, 40)\n",
      "MobilenetV3/expanded_conv_3/project/BatchNorm/gamma (40,)\n",
      "MobilenetV3/expanded_conv_3/project/BatchNorm/beta (40,)\n",
      "MobilenetV3/expanded_conv_3/project/BatchNorm/moving_mean (40,)\n",
      "MobilenetV3/expanded_conv_3/project/BatchNorm/moving_variance (40,)\n",
      "MobilenetV3/expanded_conv_4/expand/weights (1, 1, 40, 240)\n",
      "MobilenetV3/expanded_conv_4/expand/BatchNorm/gamma (240,)\n",
      "MobilenetV3/expanded_conv_4/expand/BatchNorm/beta (240,)\n",
      "MobilenetV3/expanded_conv_4/expand/BatchNorm/moving_mean (240,)\n",
      "MobilenetV3/expanded_conv_4/expand/BatchNorm/moving_variance (240,)\n",
      "MobilenetV3/expanded_conv_4/expand/hard_swish/add/y ()\n",
      "MobilenetV3/expanded_conv_4/expand/hard_swish/mul_1/y ()\n",
      "MobilenetV3/expanded_conv_4/depthwise/depthwise_weights (5, 5, 240, 1)\n",
      "MobilenetV3/expanded_conv_4/depthwise/BatchNorm/gamma (240,)\n",
      "MobilenetV3/expanded_conv_4/depthwise/BatchNorm/beta (240,)\n",
      "MobilenetV3/expanded_conv_4/depthwise/BatchNorm/moving_mean (240,)\n",
      "MobilenetV3/expanded_conv_4/depthwise/BatchNorm/moving_variance (240,)\n",
      "MobilenetV3/expanded_conv_4/depthwise/hard_swish/add/y ()\n",
      "MobilenetV3/expanded_conv_4/depthwise/hard_swish/mul_1/y ()\n",
      "MobilenetV3/expanded_conv_4/squeeze_excite/Conv/weights (1, 1, 240, 64)\n",
      "MobilenetV3/expanded_conv_4/squeeze_excite/Conv/biases (64,)\n",
      "MobilenetV3/expanded_conv_4/squeeze_excite/Conv_1/weights (1, 1, 64, 240)\n",
      "MobilenetV3/expanded_conv_4/squeeze_excite/Conv_1/biases (240,)\n",
      "MobilenetV3/expanded_conv_4/squeeze_excite/Conv_1/add/y ()\n",
      "MobilenetV3/expanded_conv_4/squeeze_excite/Conv_1/mul/y ()\n",
      "MobilenetV3/expanded_conv_4/project/weights (1, 1, 240, 40)\n",
      "MobilenetV3/expanded_conv_4/project/BatchNorm/gamma (40,)\n",
      "MobilenetV3/expanded_conv_4/project/BatchNorm/beta (40,)\n",
      "MobilenetV3/expanded_conv_4/project/BatchNorm/moving_mean (40,)\n",
      "MobilenetV3/expanded_conv_4/project/BatchNorm/moving_variance (40,)\n",
      "MobilenetV3/expanded_conv_5/expand/weights (1, 1, 40, 240)\n",
      "MobilenetV3/expanded_conv_5/expand/BatchNorm/gamma (240,)\n",
      "MobilenetV3/expanded_conv_5/expand/BatchNorm/beta (240,)\n",
      "MobilenetV3/expanded_conv_5/expand/BatchNorm/moving_mean (240,)\n",
      "MobilenetV3/expanded_conv_5/expand/BatchNorm/moving_variance (240,)\n",
      "MobilenetV3/expanded_conv_5/expand/hard_swish/add/y ()\n",
      "MobilenetV3/expanded_conv_5/expand/hard_swish/mul_1/y ()\n",
      "MobilenetV3/expanded_conv_5/depthwise/depthwise_weights (5, 5, 240, 1)\n",
      "MobilenetV3/expanded_conv_5/depthwise/BatchNorm/gamma (240,)\n",
      "MobilenetV3/expanded_conv_5/depthwise/BatchNorm/beta (240,)\n",
      "MobilenetV3/expanded_conv_5/depthwise/BatchNorm/moving_mean (240,)\n",
      "MobilenetV3/expanded_conv_5/depthwise/BatchNorm/moving_variance (240,)\n",
      "MobilenetV3/expanded_conv_5/depthwise/hard_swish/add/y ()\n",
      "MobilenetV3/expanded_conv_5/depthwise/hard_swish/mul_1/y ()\n",
      "MobilenetV3/expanded_conv_5/squeeze_excite/Conv/weights (1, 1, 240, 64)\n",
      "MobilenetV3/expanded_conv_5/squeeze_excite/Conv/biases (64,)\n",
      "MobilenetV3/expanded_conv_5/squeeze_excite/Conv_1/weights (1, 1, 64, 240)\n",
      "MobilenetV3/expanded_conv_5/squeeze_excite/Conv_1/biases (240,)\n",
      "MobilenetV3/expanded_conv_5/squeeze_excite/Conv_1/add/y ()\n",
      "MobilenetV3/expanded_conv_5/squeeze_excite/Conv_1/mul/y ()\n",
      "MobilenetV3/expanded_conv_5/project/weights (1, 1, 240, 40)\n",
      "MobilenetV3/expanded_conv_5/project/BatchNorm/gamma (40,)\n",
      "MobilenetV3/expanded_conv_5/project/BatchNorm/beta (40,)\n",
      "MobilenetV3/expanded_conv_5/project/BatchNorm/moving_mean (40,)\n",
      "MobilenetV3/expanded_conv_5/project/BatchNorm/moving_variance (40,)\n",
      "MobilenetV3/expanded_conv_6/expand/weights (1, 1, 40, 120)\n",
      "MobilenetV3/expanded_conv_6/expand/BatchNorm/gamma (120,)\n",
      "MobilenetV3/expanded_conv_6/expand/BatchNorm/beta (120,)\n",
      "MobilenetV3/expanded_conv_6/expand/BatchNorm/moving_mean (120,)\n",
      "MobilenetV3/expanded_conv_6/expand/BatchNorm/moving_variance (120,)\n",
      "MobilenetV3/expanded_conv_6/expand/hard_swish/add/y ()\n",
      "MobilenetV3/expanded_conv_6/expand/hard_swish/mul_1/y ()\n",
      "MobilenetV3/expanded_conv_6/depthwise/depthwise_weights (5, 5, 120, 1)\n",
      "MobilenetV3/expanded_conv_6/depthwise/BatchNorm/gamma (120,)\n",
      "MobilenetV3/expanded_conv_6/depthwise/BatchNorm/beta (120,)\n",
      "MobilenetV3/expanded_conv_6/depthwise/BatchNorm/moving_mean (120,)\n",
      "MobilenetV3/expanded_conv_6/depthwise/BatchNorm/moving_variance (120,)\n",
      "MobilenetV3/expanded_conv_6/depthwise/hard_swish/add/y ()\n",
      "MobilenetV3/expanded_conv_6/depthwise/hard_swish/mul_1/y ()\n",
      "MobilenetV3/expanded_conv_6/squeeze_excite/Conv/weights (1, 1, 120, 32)\n",
      "MobilenetV3/expanded_conv_6/squeeze_excite/Conv/biases (32,)\n",
      "MobilenetV3/expanded_conv_6/squeeze_excite/Conv_1/weights (1, 1, 32, 120)\n",
      "MobilenetV3/expanded_conv_6/squeeze_excite/Conv_1/biases (120,)\n",
      "MobilenetV3/expanded_conv_6/squeeze_excite/Conv_1/add/y ()\n",
      "MobilenetV3/expanded_conv_6/squeeze_excite/Conv_1/mul/y ()\n",
      "MobilenetV3/expanded_conv_6/project/weights (1, 1, 120, 48)\n",
      "MobilenetV3/expanded_conv_6/project/BatchNorm/gamma (48,)\n",
      "MobilenetV3/expanded_conv_6/project/BatchNorm/beta (48,)\n",
      "MobilenetV3/expanded_conv_6/project/BatchNorm/moving_mean (48,)\n",
      "MobilenetV3/expanded_conv_6/project/BatchNorm/moving_variance (48,)\n",
      "MobilenetV3/expanded_conv_7/expand/weights (1, 1, 48, 144)\n",
      "MobilenetV3/expanded_conv_7/expand/BatchNorm/gamma (144,)\n",
      "MobilenetV3/expanded_conv_7/expand/BatchNorm/beta (144,)\n",
      "MobilenetV3/expanded_conv_7/expand/BatchNorm/moving_mean (144,)\n",
      "MobilenetV3/expanded_conv_7/expand/BatchNorm/moving_variance (144,)\n",
      "MobilenetV3/expanded_conv_7/expand/hard_swish/add/y ()\n",
      "MobilenetV3/expanded_conv_7/expand/hard_swish/mul_1/y ()\n",
      "MobilenetV3/expanded_conv_7/depthwise/depthwise_weights (5, 5, 144, 1)\n",
      "MobilenetV3/expanded_conv_7/depthwise/BatchNorm/gamma (144,)\n",
      "MobilenetV3/expanded_conv_7/depthwise/BatchNorm/beta (144,)\n",
      "MobilenetV3/expanded_conv_7/depthwise/BatchNorm/moving_mean (144,)\n",
      "MobilenetV3/expanded_conv_7/depthwise/BatchNorm/moving_variance (144,)\n",
      "MobilenetV3/expanded_conv_7/depthwise/hard_swish/add/y ()\n",
      "MobilenetV3/expanded_conv_7/depthwise/hard_swish/mul_1/y ()\n",
      "MobilenetV3/expanded_conv_7/squeeze_excite/Conv/weights (1, 1, 144, 40)\n",
      "MobilenetV3/expanded_conv_7/squeeze_excite/Conv/biases (40,)\n",
      "MobilenetV3/expanded_conv_7/squeeze_excite/Conv_1/weights (1, 1, 40, 144)\n",
      "MobilenetV3/expanded_conv_7/squeeze_excite/Conv_1/biases (144,)\n",
      "MobilenetV3/expanded_conv_7/squeeze_excite/Conv_1/add/y ()\n",
      "MobilenetV3/expanded_conv_7/squeeze_excite/Conv_1/mul/y ()\n",
      "MobilenetV3/expanded_conv_7/project/weights (1, 1, 144, 48)\n",
      "MobilenetV3/expanded_conv_7/project/BatchNorm/gamma (48,)\n",
      "MobilenetV3/expanded_conv_7/project/BatchNorm/beta (48,)\n",
      "MobilenetV3/expanded_conv_7/project/BatchNorm/moving_mean (48,)\n",
      "MobilenetV3/expanded_conv_7/project/BatchNorm/moving_variance (48,)\n",
      "MobilenetV3/expanded_conv_8/expand/weights (1, 1, 48, 288)\n",
      "MobilenetV3/expanded_conv_8/expand/BatchNorm/gamma (288,)\n",
      "MobilenetV3/expanded_conv_8/expand/BatchNorm/beta (288,)\n",
      "MobilenetV3/expanded_conv_8/expand/BatchNorm/moving_mean (288,)\n",
      "MobilenetV3/expanded_conv_8/expand/BatchNorm/moving_variance (288,)\n",
      "MobilenetV3/expanded_conv_8/expand/hard_swish/add/y ()\n",
      "MobilenetV3/expanded_conv_8/expand/hard_swish/mul_1/y ()\n",
      "MobilenetV3/expanded_conv_8/depthwise/depthwise_weights (5, 5, 288, 1)\n",
      "MobilenetV3/expanded_conv_8/depthwise/BatchNorm/gamma (288,)\n",
      "MobilenetV3/expanded_conv_8/depthwise/BatchNorm/beta (288,)\n",
      "MobilenetV3/expanded_conv_8/depthwise/BatchNorm/moving_mean (288,)\n",
      "MobilenetV3/expanded_conv_8/depthwise/BatchNorm/moving_variance (288,)\n",
      "MobilenetV3/expanded_conv_8/depthwise/hard_swish/add/y ()\n",
      "MobilenetV3/expanded_conv_8/depthwise/hard_swish/mul_1/y ()\n",
      "MobilenetV3/expanded_conv_8/squeeze_excite/Conv/weights (1, 1, 288, 72)\n",
      "MobilenetV3/expanded_conv_8/squeeze_excite/Conv/biases (72,)\n",
      "MobilenetV3/expanded_conv_8/squeeze_excite/Conv_1/weights (1, 1, 72, 288)\n",
      "MobilenetV3/expanded_conv_8/squeeze_excite/Conv_1/biases (288,)\n",
      "MobilenetV3/expanded_conv_8/squeeze_excite/Conv_1/add/y ()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobilenetV3/expanded_conv_8/squeeze_excite/Conv_1/mul/y ()\n",
      "MobilenetV3/expanded_conv_8/project/weights (1, 1, 288, 96)\n",
      "MobilenetV3/expanded_conv_8/project/BatchNorm/gamma (96,)\n",
      "MobilenetV3/expanded_conv_8/project/BatchNorm/beta (96,)\n",
      "MobilenetV3/expanded_conv_8/project/BatchNorm/moving_mean (96,)\n",
      "MobilenetV3/expanded_conv_8/project/BatchNorm/moving_variance (96,)\n",
      "MobilenetV3/expanded_conv_9/expand/weights (1, 1, 96, 576)\n",
      "MobilenetV3/expanded_conv_9/expand/BatchNorm/gamma (576,)\n",
      "MobilenetV3/expanded_conv_9/expand/BatchNorm/beta (576,)\n",
      "MobilenetV3/expanded_conv_9/expand/BatchNorm/moving_mean (576,)\n",
      "MobilenetV3/expanded_conv_9/expand/BatchNorm/moving_variance (576,)\n",
      "MobilenetV3/expanded_conv_9/expand/hard_swish/add/y ()\n",
      "MobilenetV3/expanded_conv_9/expand/hard_swish/mul_1/y ()\n",
      "MobilenetV3/expanded_conv_9/depthwise/depthwise_weights (5, 5, 576, 1)\n",
      "MobilenetV3/expanded_conv_9/depthwise/BatchNorm/gamma (576,)\n",
      "MobilenetV3/expanded_conv_9/depthwise/BatchNorm/beta (576,)\n",
      "MobilenetV3/expanded_conv_9/depthwise/BatchNorm/moving_mean (576,)\n",
      "MobilenetV3/expanded_conv_9/depthwise/BatchNorm/moving_variance (576,)\n",
      "MobilenetV3/expanded_conv_9/depthwise/hard_swish/add/y ()\n",
      "MobilenetV3/expanded_conv_9/depthwise/hard_swish/mul_1/y ()\n",
      "MobilenetV3/expanded_conv_9/squeeze_excite/Conv/weights (1, 1, 576, 144)\n",
      "MobilenetV3/expanded_conv_9/squeeze_excite/Conv/biases (144,)\n",
      "MobilenetV3/expanded_conv_9/squeeze_excite/Conv_1/weights (1, 1, 144, 576)\n",
      "MobilenetV3/expanded_conv_9/squeeze_excite/Conv_1/biases (576,)\n",
      "MobilenetV3/expanded_conv_9/squeeze_excite/Conv_1/add/y ()\n",
      "MobilenetV3/expanded_conv_9/squeeze_excite/Conv_1/mul/y ()\n",
      "MobilenetV3/expanded_conv_9/project/weights (1, 1, 576, 96)\n",
      "MobilenetV3/expanded_conv_9/project/BatchNorm/gamma (96,)\n",
      "MobilenetV3/expanded_conv_9/project/BatchNorm/beta (96,)\n",
      "MobilenetV3/expanded_conv_9/project/BatchNorm/moving_mean (96,)\n",
      "MobilenetV3/expanded_conv_9/project/BatchNorm/moving_variance (96,)\n",
      "MobilenetV3/expanded_conv_10/expand/weights (1, 1, 96, 576)\n",
      "MobilenetV3/expanded_conv_10/expand/BatchNorm/gamma (576,)\n",
      "MobilenetV3/expanded_conv_10/expand/BatchNorm/beta (576,)\n",
      "MobilenetV3/expanded_conv_10/expand/BatchNorm/moving_mean (576,)\n",
      "MobilenetV3/expanded_conv_10/expand/BatchNorm/moving_variance (576,)\n",
      "MobilenetV3/expanded_conv_10/expand/hard_swish/add/y ()\n",
      "MobilenetV3/expanded_conv_10/expand/hard_swish/mul_1/y ()\n",
      "MobilenetV3/expanded_conv_10/depthwise/depthwise_weights (5, 5, 576, 1)\n",
      "MobilenetV3/expanded_conv_10/depthwise/BatchNorm/gamma (576,)\n",
      "MobilenetV3/expanded_conv_10/depthwise/BatchNorm/beta (576,)\n",
      "MobilenetV3/expanded_conv_10/depthwise/BatchNorm/moving_mean (576,)\n",
      "MobilenetV3/expanded_conv_10/depthwise/BatchNorm/moving_variance (576,)\n",
      "MobilenetV3/expanded_conv_10/depthwise/hard_swish/add/y ()\n",
      "MobilenetV3/expanded_conv_10/depthwise/hard_swish/mul_1/y ()\n",
      "MobilenetV3/expanded_conv_10/squeeze_excite/Conv/weights (1, 1, 576, 144)\n",
      "MobilenetV3/expanded_conv_10/squeeze_excite/Conv/biases (144,)\n",
      "MobilenetV3/expanded_conv_10/squeeze_excite/Conv_1/weights (1, 1, 144, 576)\n",
      "MobilenetV3/expanded_conv_10/squeeze_excite/Conv_1/biases (576,)\n",
      "MobilenetV3/expanded_conv_10/squeeze_excite/Conv_1/add/y ()\n",
      "MobilenetV3/expanded_conv_10/squeeze_excite/Conv_1/mul/y ()\n",
      "MobilenetV3/expanded_conv_10/project/weights (1, 1, 576, 96)\n",
      "MobilenetV3/expanded_conv_10/project/BatchNorm/gamma (96,)\n",
      "MobilenetV3/expanded_conv_10/project/BatchNorm/beta (96,)\n",
      "MobilenetV3/expanded_conv_10/project/BatchNorm/moving_mean (96,)\n",
      "MobilenetV3/expanded_conv_10/project/BatchNorm/moving_variance (96,)\n",
      "MobilenetV3/Conv_1/weights (1, 1, 96, 576)\n",
      "MobilenetV3/Conv_1/BatchNorm/gamma (576,)\n",
      "MobilenetV3/Conv_1/BatchNorm/beta (576,)\n",
      "MobilenetV3/Conv_1/BatchNorm/moving_mean (576,)\n",
      "MobilenetV3/Conv_1/BatchNorm/moving_variance (576,)\n",
      "MobilenetV3/Conv_1/hard_swish/add/y ()\n",
      "MobilenetV3/Conv_1/hard_swish/mul_1/y ()\n",
      "MobilenetV3/Conv_2/weights (1, 1, 576, 1024)\n",
      "MobilenetV3/Conv_2/biases (1024,)\n",
      "MobilenetV3/Conv_2/hard_swish/add/y ()\n",
      "MobilenetV3/Conv_2/hard_swish/mul_1/y ()\n",
      "MobilenetV3/Logits/Conv2d_1c_1x1/weights (1, 1, 1024, 1001)\n",
      "MobilenetV3/Logits/Conv2d_1c_1x1/biases (1001,)\n",
      "MobilenetV3/Predictions/Reshape/shape (2,)\n"
     ]
    }
   ],
   "source": [
    "for name, weight in const_weights:\n",
    "    print(name, weight.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bulit MobileNetV3-Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T14:02:54.724210Z",
     "start_time": "2020-02-24T14:02:52.781752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/liew/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:153: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, DepthwiseConv2D, Dense, GlobalAveragePooling2D, AveragePooling2D\n",
    "from keras.layers import Activation, BatchNormalization, Add, Multiply, Reshape\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "\n",
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "class MobileNetBase:\n",
    "    def __init__(self, shape, n_class, alpha=1.0):\n",
    "        \"\"\"Init\n",
    "        \n",
    "        # Arguments\n",
    "            input_shape: An integer or tuple/list of 3 integers, shape\n",
    "                of input tensor.\n",
    "            n_class: Integer, number of classes.\n",
    "            alpha: Integer, width multiplier.\n",
    "        \"\"\"\n",
    "        self.shape = shape\n",
    "        self.n_class = n_class\n",
    "        self.alpha = alpha\n",
    "\n",
    "#     def _relu6(self, x):\n",
    "#         \"\"\"Relu 6\n",
    "#         \"\"\"\n",
    "#         return K.relu(x, max_value=6.0)\n",
    "\n",
    "    def _hard_swish(self, x):\n",
    "        \"\"\"Hard swish\n",
    "        \"\"\"\n",
    "        return x * K.relu(x + 3.0, max_value=6.0) / 6.0\n",
    "\n",
    "    def _return_activation(self, x, nl):\n",
    "        \"\"\"Convolution Block\n",
    "        This function defines a activation choice.\n",
    "        # Arguments\n",
    "            x: Tensor, input tensor of conv layer.\n",
    "            nl: String, nonlinearity activation type.\n",
    "        # Returns\n",
    "            Output tensor.\n",
    "        \"\"\"\n",
    "        if nl == 'HS':\n",
    "            x = Activation(self._hard_swish)(x)\n",
    "        if nl == 'RE':\n",
    "            x = Activation('relu')(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _conv_block(self, inputs, filters, kernel, strides, nl,use_bias=False):\n",
    "        \"\"\"Convolution Block\n",
    "        This function defines a 2D convolution operation with BN and activation.\n",
    "        # Arguments\n",
    "            inputs: Tensor, input tensor of conv layer.\n",
    "            filters: Integer, the dimensionality of the output space.\n",
    "            kernel: An integer or tuple/list of 2 integers, specifying the\n",
    "                width and height of the 2D convolution window.\n",
    "            strides: An integer or tuple/list of 2 integers,\n",
    "                specifying the strides of the convolution along the width and height.\n",
    "                Can be a single integer to specify the same value for\n",
    "                all spatial dimensions.\n",
    "            nl: String, nonlinearity activation type.\n",
    "        # Returns\n",
    "            Output tensor.\n",
    "        \"\"\"\n",
    "\n",
    "        channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "        x = Conv2D(filters, kernel, padding='same', strides=strides,use_bias=use_bias)(inputs)\n",
    "        x = BatchNormalization(axis=channel_axis)(x)\n",
    "\n",
    "        return self._return_activation(x, nl)\n",
    "\n",
    "    \n",
    "    def _squeeze(self, inputs):\n",
    "        \"\"\"Squeeze and Excitation.\n",
    "        This function defines a squeeze structure.\n",
    "        # Arguments\n",
    "            inputs: Tensor, input tensor of conv layer.\n",
    "        \"\"\"\n",
    "        input_channels = int(inputs.shape[-1])\n",
    "        squeeze_channels = _make_divisible(input_channels / 4, divisor=8)\n",
    "        x = AveragePooling2D(pool_size=[int(inputs.shape[1]),int(inputs.shape[2])])(inputs)\n",
    "        \n",
    "#         torch.nn.AdaptiveAvgPool2d(output_size=(1, 1)),\n",
    "        x = Conv2D(squeeze_channels, kernel_size=1, use_bias=True,activation='relu')(x)\n",
    "        x = Conv2D(input_channels, kernel_size=1, use_bias=True,activation='hard_sigmoid')(x)\n",
    "#         x = Reshape((1, 1, input_channels))(x)\n",
    "        x = Multiply()([inputs, x])\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _bottleneck(self, inputs, filters, kernel, e, s, squeeze, nl):\n",
    "        \"\"\"Bottleneck\n",
    "        This function defines a basic bottleneck structure.\n",
    "        # Arguments\n",
    "            inputs: Tensor, input tensor of conv layer.\n",
    "            filters: Integer, the dimensionality of the output space.\n",
    "            kernel: An integer or tuple/list of 2 integers, specifying the\n",
    "                width and height of the 2D convolution window.\n",
    "            e: Integer, expansion factor.\n",
    "                t is always applied to the input size.\n",
    "            s: An integer or tuple/list of 2 integers,specifying the strides\n",
    "                of the convolution along the width and height.Can be a single\n",
    "                integer to specify the same value for all spatial dimensions.\n",
    "            squeeze: Boolean, Whether to use the squeeze.\n",
    "            nl: String, nonlinearity activation type.\n",
    "        # Returns\n",
    "            Output tensor.\n",
    "        \"\"\"\n",
    "\n",
    "        channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "        input_shape = K.int_shape(inputs)\n",
    "\n",
    "        tchannel = int(e)\n",
    "        cchannel = int(self.alpha * filters)\n",
    "\n",
    "        r = s == 1 and input_shape[3] == filters\n",
    "        if e > filters:\n",
    "            x = self._conv_block(inputs, tchannel, (1, 1), (1, 1), nl)\n",
    "        else:\n",
    "            x = inputs\n",
    "        x = DepthwiseConv2D(kernel, strides=(s, s), depth_multiplier=1, padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization(axis=channel_axis)(x)\n",
    "        x = self._return_activation(x, nl)\n",
    "\n",
    "        if squeeze:\n",
    "            x = self._squeeze(x)\n",
    "\n",
    "        x = Conv2D(cchannel, (1, 1), strides=(1, 1), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization(axis=channel_axis)(x)\n",
    "\n",
    "        if r:\n",
    "            x = Add()([x, inputs])\n",
    "\n",
    "        return x\n",
    "\n",
    "    def build(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\"\"\"MobileNet v3 small models for Keras.\n",
    "# Reference\n",
    "    [Searching for MobileNetV3](https://arxiv.org/abs/1905.02244?context=cs)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, GlobalAveragePooling2D, Reshape\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "# from model.mobilenet_base import MobileNetBase\n",
    "\n",
    "\n",
    "class MobileNetV3_Small(MobileNetBase):\n",
    "    def __init__(self, shape, n_class, alpha=1.0, include_top=True):\n",
    "        \"\"\"Init.\n",
    "        # Arguments\n",
    "            input_shape: An integer or tuple/list of 3 integers, shape\n",
    "                of input tensor.\n",
    "            n_class: Integer, number of classes.\n",
    "            alpha: Integer, width multiplier.\n",
    "            include_top: if inculde classification layer.\n",
    "        # Returns\n",
    "            MobileNetv3 model.\n",
    "        \"\"\"\n",
    "        super(MobileNetV3_Small, self).__init__(shape, n_class, alpha)\n",
    "        self.include_top = include_top\n",
    "\n",
    "    def build(self, plot=False):\n",
    "        \"\"\"build MobileNetV3 Small.\n",
    "        # Arguments\n",
    "            plot: Boolean, weather to plot model.\n",
    "        # Returns\n",
    "            model: Model, model.\n",
    "        \"\"\"\n",
    "        inputs = Input(shape=self.shape)\n",
    "\n",
    "        x = self._conv_block(inputs, 16, (3, 3), strides=(2, 2), nl='HS',use_bias=False)\n",
    "\n",
    "        x = self._bottleneck(x, 16, (3, 3), e=16, s=2, squeeze=True, nl='RE')\n",
    "        x = self._bottleneck(x, 24, (3, 3), e=72, s=2, squeeze=False, nl='RE')\n",
    "        x = self._bottleneck(x, 24, (3, 3), e=88, s=1, squeeze=False, nl='RE')\n",
    "        x = self._bottleneck(x, 40, (5, 5), e=96, s=2, squeeze=True, nl='HS')\n",
    "        x = self._bottleneck(x, 40, (5, 5), e=240, s=1, squeeze=True, nl='HS')\n",
    "        x = self._bottleneck(x, 40, (5, 5), e=240, s=1, squeeze=True, nl='HS')\n",
    "        x = self._bottleneck(x, 48, (5, 5), e=120, s=1, squeeze=True, nl='HS')\n",
    "        x = self._bottleneck(x, 48, (5, 5), e=144, s=1, squeeze=True, nl='HS')\n",
    "        x = self._bottleneck(x, 96, (5, 5), e=288, s=2, squeeze=True, nl='HS')\n",
    "        x = self._bottleneck(x, 96, (5, 5), e=576, s=1, squeeze=True, nl='HS')\n",
    "        x = self._bottleneck(x, 96, (5, 5), e=576, s=1, squeeze=True, nl='HS')\n",
    "\n",
    "        x = self._conv_block(x, 576, (1, 1), strides=(1, 1), nl='HS')\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Reshape((1, 1, 576))(x)\n",
    "\n",
    "        x = Conv2D(1024, (1, 1), padding='same')(x)\n",
    "        x = self._return_activation(x, 'HS')\n",
    "\n",
    "        if self.include_top:\n",
    "            x = Conv2D(self.n_class, (1, 1), padding='same', activation='softmax')(x)\n",
    "            x = Reshape((self.n_class,))(x)\n",
    "\n",
    "        model = Model(inputs, x)\n",
    "\n",
    "        if plot:\n",
    "            plot_model(model, to_file='images/MobileNetv3_small.png', show_shapes=True)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T14:03:04.041982Z",
     "start_time": "2020-02-24T14:02:58.004434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/liew/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/liew/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/liew/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/liew/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/liew/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/liew/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/liew/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/liew/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/liew/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/liew/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/liew/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = MobileNetV3_Small(shape=(224,224,3), n_class=1001).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T14:03:09.003581Z",
     "start_time": "2020-02-24T14:03:08.813744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 112, 112, 16) 432         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 112, 112, 16) 64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 16) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_1 (DepthwiseCo (None, 56, 56, 16)   144         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 56, 56, 16)   64          depthwise_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 16)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 1, 1, 8)      136         average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 1, 1, 16)     144         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 56, 56, 16)   0           activation_2[0][0]               \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 56, 56, 16)   256         multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 56, 56, 16)   64          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 56, 56, 72)   1152        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 56, 56, 72)   288         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 72)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_2 (DepthwiseCo (None, 28, 28, 72)   648         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 28, 28, 72)   288         depthwise_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 28, 28, 72)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 28, 28, 24)   1728        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 28, 28, 24)   96          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 28, 28, 88)   2112        batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 28, 28, 88)   352         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 28, 28, 88)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_3 (DepthwiseCo (None, 28, 28, 88)   792         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 28, 28, 88)   352         depthwise_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 28, 28, 88)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 28, 28, 24)   2112        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 28, 28, 24)   96          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 28, 28, 24)   0           batch_normalization_9[0][0]      \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 28, 28, 96)   2304        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 28, 28, 96)   384         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 28, 28, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_4 (DepthwiseCo (None, 14, 14, 96)   2400        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 14, 14, 96)   384         depthwise_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 14, 14, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 1, 1, 96)     0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 1, 1, 24)     2328        average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 1, 1, 96)     2400        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 14, 14, 96)   0           activation_8[0][0]               \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 14, 14, 40)   3840        multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 14, 14, 40)   160         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 14, 14, 240)  9600        batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 14, 14, 240)  960         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 14, 14, 240)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_5 (DepthwiseCo (None, 14, 14, 240)  6000        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 14, 14, 240)  960         depthwise_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 14, 14, 240)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 1, 1, 240)    0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 1, 1, 64)     15424       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 1, 1, 240)    15600       conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 14, 14, 240)  0           activation_10[0][0]              \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 14, 14, 40)   9600        multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 14, 14, 40)   160         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 14, 14, 40)   0           batch_normalization_15[0][0]     \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 14, 14, 240)  9600        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 14, 14, 240)  960         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 14, 14, 240)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_6 (DepthwiseCo (None, 14, 14, 240)  6000        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 14, 14, 240)  960         depthwise_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 14, 14, 240)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 1, 1, 240)    0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 1, 1, 64)     15424       average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 1, 1, 240)    15600       conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 14, 14, 240)  0           activation_12[0][0]              \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 14, 14, 40)   9600        multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 14, 14, 40)   160         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 40)   0           batch_normalization_18[0][0]     \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 14, 14, 120)  4800        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 14, 14, 120)  480         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 14, 14, 120)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_7 (DepthwiseCo (None, 14, 14, 120)  3000        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 14, 14, 120)  480         depthwise_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 14, 14, 120)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 1, 1, 120)    0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 1, 1, 32)     3872        average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 1, 1, 120)    3960        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 14, 14, 120)  0           activation_14[0][0]              \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 14, 14, 48)   5760        multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 14, 14, 48)   192         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 14, 14, 144)  6912        batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 14, 14, 144)  576         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 14, 14, 144)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_8 (DepthwiseCo (None, 14, 14, 144)  3600        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 14, 14, 144)  576         depthwise_conv2d_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 14, 14, 144)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 1, 1, 144)    0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 1, 1, 40)     5800        average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 1, 1, 144)    5904        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 14, 14, 144)  0           activation_16[0][0]              \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 14, 14, 48)   6912        multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 14, 14, 48)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 14, 14, 48)   0           batch_normalization_24[0][0]     \n",
      "                                                                 batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 14, 14, 288)  13824       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 14, 14, 288)  1152        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 14, 14, 288)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_9 (DepthwiseCo (None, 7, 7, 288)    7200        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 7, 7, 288)    1152        depthwise_conv2d_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 7, 7, 288)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 1, 1, 288)    0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 1, 1, 72)     20808       average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 1, 1, 288)    21024       conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 7, 7, 288)    0           activation_18[0][0]              \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 7, 7, 96)     27648       multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 7, 7, 96)     384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 7, 7, 576)    55296       batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 7, 7, 576)    2304        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 7, 7, 576)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_10 (DepthwiseC (None, 7, 7, 576)    14400       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 7, 7, 576)    2304        depthwise_conv2d_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 7, 7, 576)    0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 1, 1, 576)    0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 1, 1, 144)    83088       average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 1, 1, 576)    83520       conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 7, 7, 576)    0           activation_20[0][0]              \n",
      "                                                                 conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 7, 7, 96)     55296       multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 7, 7, 96)     384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 7, 7, 96)     0           batch_normalization_30[0][0]     \n",
      "                                                                 batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 7, 7, 576)    55296       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 7, 7, 576)    2304        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 7, 7, 576)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_11 (DepthwiseC (None, 7, 7, 576)    14400       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 7, 7, 576)    2304        depthwise_conv2d_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 7, 7, 576)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 1, 1, 576)    0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 1, 1, 144)    83088       average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 1, 1, 576)    83520       conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 7, 7, 576)    0           activation_22[0][0]              \n",
      "                                                                 conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 7, 7, 96)     55296       multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 7, 7, 96)     384         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 7, 7, 96)     0           batch_normalization_33[0][0]     \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 7, 7, 576)    55296       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 7, 7, 576)    2304        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 7, 7, 576)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 576)          0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 1, 576)    0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 1, 1, 1024)   590848      reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 1, 1, 1024)   0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 1, 1, 1001)   1026025     activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1001)         0           conv2d_43[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,555,993\n",
      "Trainable params: 2,543,881\n",
      "Non-trainable params: 12,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load weights to every layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T14:06:09.950731Z",
     "start_time": "2020-02-24T14:06:09.700263Z"
    }
   },
   "outputs": [],
   "source": [
    "j_cnt = 0\n",
    "for i, l in enumerate(model.layers):\n",
    "    if not len(l.weights):\n",
    "        continue\n",
    "#     print(i, l.name, len(l.weights))\n",
    "#     print([w.shape for w in l.weights])\n",
    "    \n",
    "    layer_ws = []\n",
    "    if 'batch_normalization' in l.name:\n",
    "        layer_ws = [w for n,w in const_weights[j_cnt:j_cnt+4]]\n",
    "        l.set_weights(layer_ws)\n",
    "        j_cnt += 4\n",
    "    elif 'conv2d' in  l.name:\n",
    "        layer_ws = [w for n,w in const_weights[j_cnt:j_cnt+len(l.weights)]]\n",
    "        l.set_weights(layer_ws)\n",
    "        j_cnt += len(l.weights)\n",
    "    else:\n",
    "        print('skip', l.name, len(l.weights))\n",
    "    \n",
    "    while len(const_weights[j_cnt][1].shape) == 0:\n",
    "        j_cnt += 1\n",
    "    \n",
    "    \n",
    "\n",
    "# model.save_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T11:35:19.191783Z",
     "start_time": "2020-02-23T11:35:18.797745Z"
    }
   },
   "source": [
    "# Test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T14:09:27.686167Z",
     "start_time": "2020-02-24T14:09:27.630995Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('cat.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (224, 224))\n",
    "img = (img/127.5) - 1 \n",
    "\n",
    "prob = model.predict(np.expand_dims(img,0))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T14:09:35.870051Z",
     "start_time": "2020-02-24T14:09:35.850715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([278, 275, 279, 272, 288])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob.argsort()[::-1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
